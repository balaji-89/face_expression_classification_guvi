{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "from dataset import get_dataloaders\n",
    "from utils import get_model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description='USTC Computer Vision Final Project')\n",
    "parser.add_argument('--batch_size', default=128, type=int)\n",
    "parser.add_argument('--seed', default=0, type=int)\n",
    "parser.add_argument('--data_path', default='datasets/fer2013/fer2013.csv', type=str)\n",
    "parser.add_argument('--checkpoint', default='', type=str)\n",
    "parser.add_argument('--arch', default=\"ResNet18\", type=str)\n",
    "parser.add_argument('--Ncrop', default=True, type=eval)\n",
    "\n",
    "\n",
    "def correct_count(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the top k corrrect count for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluate(net, dataloader, loss_fn, Ncrop, device):\n",
    "    net = net.eval()\n",
    "    loss_tr, n_samples = 0.0, 0.0\n",
    "\n",
    "    y_pred = []\n",
    "    y_gt = []\n",
    "\n",
    "    correct_count1 = 0\n",
    "    correct_count2 = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        if Ncrop:\n",
    "            # fuse crops and batchsize\n",
    "            bs, ncrops, c, h, w = inputs.shape\n",
    "            inputs = inputs.view(-1, c, h, w)\n",
    "\n",
    "            # forward\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # combine results across the crops\n",
    "            outputs = outputs.view(bs, ncrops, -1)\n",
    "            outputs = torch.sum(outputs, dim=1) / ncrops\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # calculate performance metrics\n",
    "        loss_tr += loss.item()\n",
    "\n",
    "        # accuracy\n",
    "        counts = correct_count(outputs, labels, topk=(1, 2))\n",
    "        correct_count1 += counts[0].item()\n",
    "        correct_count2 += counts[1].item()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "\n",
    "        y_pred.extend(pred.item() for pred in preds)\n",
    "        y_gt.extend(y.item() for y in labels)\n",
    "\n",
    "    acc1 = 100 * correct_count1 / n_samples\n",
    "    acc2 = 100 * correct_count2 / n_samples\n",
    "    loss = loss_tr / n_samples\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"Top 1 Accuracy: %2.6f %%\" % acc1)\n",
    "    print(\"Top 2 Accuracy: %2.6f %%\" % acc2)\n",
    "    print(\"Loss: %2.6f\" % loss)\n",
    "    print(\"Precision: %2.6f\" % precision_score(y_gt, y_pred, average='micro'))\n",
    "    print(\"Recall: %2.6f\" % recall_score(y_gt, y_pred, average='micro'))\n",
    "    print(\"F1 Score: %2.6f\" % f1_score(y_gt, y_pred, average='micro'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_gt, y_pred), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "--------------------------------------------------------\n",
      "Top 1 Accuracy: 73.711340 %\n",
      "Top 2 Accuracy: 86.263583 %\n",
      "Loss: 0.014158\n",
      "Precision: 0.737113\n",
      "Recall: 0.737113\n",
      "F1 Score: 0.737113\n",
      "Confusion Matrix:\n",
      " [[ 643    5   76   25  127   16   66]\n",
      " [  24   73    3    3    5    1    2]\n",
      " [  91    2  576   23  185   67   80]\n",
      " [  27    0   15 1584   27   38   83]\n",
      " [  99    0  102   32  805   13  196]\n",
      " [  15    0   54   32   15  701   14]\n",
      " [  50    1   41   57  159   16  909]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # args = parser.parse_args()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    checkpoint = torch.load('./weights/best_checkpoint.tar',map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    test_loader = get_dataloaders(augment=False)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        print(\"Test\")\n",
    "        evaluate(model, test_loader, loss_fn, True, device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
