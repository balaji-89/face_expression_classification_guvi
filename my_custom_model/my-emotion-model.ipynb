{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import keras_tuner as kt\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def build_model(hp):\n","    model = Sequential()\n","    \n","    # Conv Layer 1\n","    model.add(Conv2D(\n","        filters=hp.Choice('conv1_filters', [16, 32, 64]),  \n","        kernel_size=hp.Choice('conv1_kernel', [3, 5]),  \n","        activation='relu',\n","        input_shape=(48, 48, 1)\n","    ))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D((2, 2)))\n","    \n","    # Conv Layer 2\n","    model.add(Conv2D(\n","        filters=hp.Choice('conv2_filters', [32, 64, 128]),\n","        kernel_size=hp.Choice('conv2_kernel', [3, 5]),\n","        activation='relu'\n","    ))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D((2, 2)))\n","    \n","    # Conv Layer 3\n","    model.add(Conv2D(\n","        filters=hp.Choice('conv3_filters', [64, 128, 256]),\n","        kernel_size=3,\n","        activation='relu'\n","    ))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D((2, 2)))\n","    \n","    # Dense Layers\n","    model.add(Flatten())\n","    model.add(Dense(\n","        units=hp.Choice('dense_units', [64, 128, 256]),\n","        activation='relu'\n","    ))\n","    model.add(Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n","    \n","    # Output Layer\n","    model.add(Dense(7, activation='softmax'))\n","    \n","    # Compile Model\n","    model.compile(\n","        optimizer=hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    \n","    return model\n","\n","# Create a tuner\n","tuner = kt.Hyperband(\n","    build_model,\n","    objective='val_accuracy',\n","    max_epochs=20,\n","    factor=3,\n","    directory='hyperparameter_tuning',\n","    project_name='emotion_recognition'\n",")\n","\n","# Load Data\n","train_dataset = tf.keras.utils.image_dataset_from_directory(\n","    'dataset/train',\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=123,\n","    image_size=(48, 48),\n","    batch_size=32,\n","    color_mode=\"grayscale\"\n",")\n","\n","validation_dataset = tf.keras.utils.image_dataset_from_directory(\n","    'dataset/train',\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=123,\n","    image_size=(48, 48),\n","    batch_size=32,\n","    color_mode=\"grayscale\"\n",")\n","\n","# Run the search\n","tuner.search(train_dataset, validation_data=validation_dataset, epochs=20)\n","\n","# Get the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","model = tuner.hypermodel.build(best_hps)\n","\n","# Train the best model\n","history = model.fit(train_dataset, validation_data=validation_dataset, epochs=50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-22T09:30:20.371249Z","iopub.status.busy":"2024-12-22T09:30:20.370932Z","iopub.status.idle":"2024-12-22T09:41:09.087063Z","shell.execute_reply":"2024-12-22T09:41:09.086132Z","shell.execute_reply.started":"2024-12-22T09:30:20.371222Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28709 files belonging to 7 classes.\n","Using 21532 files for training.\n","Found 28709 files belonging to 7 classes.\n","Using 7177 files for validation.\n","Found 7178 files belonging to 7 classes.\n","Epoch 1/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.2363 - loss: 2.4001 - val_accuracy: 0.2476 - val_loss: 1.8162\n","Epoch 2/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2499 - loss: 1.8077 - val_accuracy: 0.2735 - val_loss: 1.7607\n","Epoch 3/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2713 - loss: 1.7617 - val_accuracy: 0.2954 - val_loss: 1.7072\n","Epoch 4/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2971 - loss: 1.7245 - val_accuracy: 0.3488 - val_loss: 1.6622\n","Epoch 5/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3399 - loss: 1.6542 - val_accuracy: 0.3915 - val_loss: 1.5642\n","Epoch 6/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.3735 - loss: 1.5948 - val_accuracy: 0.4074 - val_loss: 1.5409\n","Epoch 7/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3990 - loss: 1.5437 - val_accuracy: 0.4145 - val_loss: 1.5110\n","Epoch 8/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4189 - loss: 1.5048 - val_accuracy: 0.4325 - val_loss: 1.4753\n","Epoch 9/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4348 - loss: 1.4662 - val_accuracy: 0.4611 - val_loss: 1.4505\n","Epoch 10/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4449 - loss: 1.4432 - val_accuracy: 0.4517 - val_loss: 1.4307\n","Epoch 11/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4521 - loss: 1.4192 - val_accuracy: 0.4618 - val_loss: 1.4123\n","Epoch 12/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4631 - loss: 1.3912 - val_accuracy: 0.4683 - val_loss: 1.4420\n","Epoch 13/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4714 - loss: 1.3826 - val_accuracy: 0.4403 - val_loss: 1.4760\n","Epoch 14/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4753 - loss: 1.3670 - val_accuracy: 0.4849 - val_loss: 1.3755\n","Epoch 15/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4871 - loss: 1.3452 - val_accuracy: 0.4905 - val_loss: 1.3486\n","Epoch 16/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4881 - loss: 1.3335 - val_accuracy: 0.4949 - val_loss: 1.3377\n","Epoch 17/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4918 - loss: 1.3295 - val_accuracy: 0.5033 - val_loss: 1.3312\n","Epoch 18/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4965 - loss: 1.3183 - val_accuracy: 0.4878 - val_loss: 1.3590\n","Epoch 19/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4966 - loss: 1.3102 - val_accuracy: 0.4921 - val_loss: 1.3618\n","Epoch 20/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5040 - loss: 1.3137 - val_accuracy: 0.5079 - val_loss: 1.3319\n","Epoch 21/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5071 - loss: 1.2841 - val_accuracy: 0.5012 - val_loss: 1.3299\n","Epoch 22/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5092 - loss: 1.2822 - val_accuracy: 0.5024 - val_loss: 1.3116\n","Epoch 23/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5139 - loss: 1.2739 - val_accuracy: 0.5098 - val_loss: 1.3140\n","Epoch 24/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5151 - loss: 1.2618 - val_accuracy: 0.5108 - val_loss: 1.3017\n","Epoch 25/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5227 - loss: 1.2584 - val_accuracy: 0.5003 - val_loss: 1.3365\n","Epoch 26/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5207 - loss: 1.2621 - val_accuracy: 0.5164 - val_loss: 1.2766\n","Epoch 27/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5269 - loss: 1.2572 - val_accuracy: 0.4914 - val_loss: 1.3767\n","Epoch 28/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5226 - loss: 1.2475 - val_accuracy: 0.5398 - val_loss: 1.2507\n","Epoch 29/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 1.2348 - val_accuracy: 0.5155 - val_loss: 1.2895\n","Epoch 30/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5307 - loss: 1.2306 - val_accuracy: 0.5147 - val_loss: 1.2990\n","Epoch 31/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5303 - loss: 1.2288 - val_accuracy: 0.5072 - val_loss: 1.3463\n","Epoch 32/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5395 - loss: 1.2151 - val_accuracy: 0.5215 - val_loss: 1.2760\n","Epoch 33/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5441 - loss: 1.2081 - val_accuracy: 0.5328 - val_loss: 1.2707\n","Epoch 34/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5497 - loss: 1.2073 - val_accuracy: 0.5445 - val_loss: 1.2473\n","Epoch 35/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5391 - loss: 1.2078 - val_accuracy: 0.5264 - val_loss: 1.2767\n","Epoch 36/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5423 - loss: 1.2043 - val_accuracy: 0.5391 - val_loss: 1.2625\n","Epoch 37/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5430 - loss: 1.2001 - val_accuracy: 0.5360 - val_loss: 1.2628\n","Epoch 38/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5525 - loss: 1.1876 - val_accuracy: 0.5452 - val_loss: 1.2390\n","Epoch 39/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5505 - loss: 1.1925 - val_accuracy: 0.5194 - val_loss: 1.2845\n","Epoch 40/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5590 - loss: 1.1776 - val_accuracy: 0.5420 - val_loss: 1.2488\n","Epoch 41/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5556 - loss: 1.1697 - val_accuracy: 0.5399 - val_loss: 1.2582\n","Epoch 42/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.5573 - loss: 1.1681 - val_accuracy: 0.5343 - val_loss: 1.2645\n","Epoch 43/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5586 - loss: 1.1731 - val_accuracy: 0.5233 - val_loss: 1.2910\n","Epoch 44/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 1.1604 - val_accuracy: 0.5424 - val_loss: 1.2518\n","Epoch 45/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5629 - loss: 1.1667 - val_accuracy: 0.5317 - val_loss: 1.2724\n","Epoch 46/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5657 - loss: 1.1559 - val_accuracy: 0.5389 - val_loss: 1.2720\n","Epoch 47/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5602 - loss: 1.1571 - val_accuracy: 0.5491 - val_loss: 1.2421\n","Epoch 48/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5660 - loss: 1.1582 - val_accuracy: 0.5417 - val_loss: 1.2623\n","Epoch 49/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5665 - loss: 1.1551 - val_accuracy: 0.5426 - val_loss: 1.2987\n","Epoch 50/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5694 - loss: 1.1481 - val_accuracy: 0.5350 - val_loss: 1.2705\n","Epoch 51/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5759 - loss: 1.1354 - val_accuracy: 0.5334 - val_loss: 1.2801\n","Epoch 52/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5731 - loss: 1.1292 - val_accuracy: 0.5506 - val_loss: 1.2500\n","Epoch 53/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5729 - loss: 1.1277 - val_accuracy: 0.5442 - val_loss: 1.2777\n","Epoch 54/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5738 - loss: 1.1338 - val_accuracy: 0.5318 - val_loss: 1.2933\n","Epoch 55/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5745 - loss: 1.1268 - val_accuracy: 0.5403 - val_loss: 1.2789\n","Epoch 56/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5776 - loss: 1.1206 - val_accuracy: 0.5346 - val_loss: 1.2792\n","Epoch 57/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.5841 - loss: 1.1124 - val_accuracy: 0.5585 - val_loss: 1.2325\n","Epoch 58/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5897 - loss: 1.0983 - val_accuracy: 0.5523 - val_loss: 1.2455\n","Epoch 59/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5799 - loss: 1.1089 - val_accuracy: 0.5526 - val_loss: 1.2536\n","Epoch 60/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5832 - loss: 1.1062 - val_accuracy: 0.5515 - val_loss: 1.2334\n","Epoch 61/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5836 - loss: 1.1104 - val_accuracy: 0.5526 - val_loss: 1.2586\n","Epoch 62/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5879 - loss: 1.1022 - val_accuracy: 0.5497 - val_loss: 1.2665\n","Epoch 63/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5824 - loss: 1.1095 - val_accuracy: 0.5467 - val_loss: 1.2675\n","Epoch 64/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 1.1029 - val_accuracy: 0.5412 - val_loss: 1.2756\n","Epoch 65/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5875 - loss: 1.0944 - val_accuracy: 0.5438 - val_loss: 1.2577\n","Epoch 66/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5960 - loss: 1.0890 - val_accuracy: 0.5611 - val_loss: 1.2332\n","Epoch 67/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5889 - loss: 1.0896 - val_accuracy: 0.5582 - val_loss: 1.2393\n","Epoch 68/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 1.0864 - val_accuracy: 0.5438 - val_loss: 1.2692\n","Epoch 69/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5916 - loss: 1.0937 - val_accuracy: 0.5565 - val_loss: 1.2453\n","Epoch 70/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5934 - loss: 1.0691 - val_accuracy: 0.5540 - val_loss: 1.2372\n","Epoch 71/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5917 - loss: 1.0755 - val_accuracy: 0.5615 - val_loss: 1.2388\n","Epoch 72/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5979 - loss: 1.0657 - val_accuracy: 0.5545 - val_loss: 1.2250\n","Epoch 73/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6011 - loss: 1.0661 - val_accuracy: 0.5558 - val_loss: 1.2392\n","Epoch 74/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6018 - loss: 1.0610 - val_accuracy: 0.5476 - val_loss: 1.3023\n","Epoch 75/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5996 - loss: 1.0595 - val_accuracy: 0.5586 - val_loss: 1.2041\n","Epoch 76/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6006 - loss: 1.0500 - val_accuracy: 0.5520 - val_loss: 1.2523\n","Epoch 77/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6054 - loss: 1.0604 - val_accuracy: 0.5572 - val_loss: 1.2418\n","Epoch 78/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6084 - loss: 1.0478 - val_accuracy: 0.5515 - val_loss: 1.2913\n","Epoch 79/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6039 - loss: 1.0552 - val_accuracy: 0.5500 - val_loss: 1.2523\n","Epoch 80/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6036 - loss: 1.0485 - val_accuracy: 0.5644 - val_loss: 1.2321\n","Epoch 81/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6092 - loss: 1.0454 - val_accuracy: 0.5410 - val_loss: 1.2918\n","Epoch 82/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6041 - loss: 1.0546 - val_accuracy: 0.5505 - val_loss: 1.2734\n","Epoch 83/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6137 - loss: 1.0451 - val_accuracy: 0.5672 - val_loss: 1.2190\n","Epoch 84/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 1.0336 - val_accuracy: 0.5548 - val_loss: 1.2490\n","Epoch 85/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6131 - loss: 1.0374 - val_accuracy: 0.5558 - val_loss: 1.2464\n","Epoch 86/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6112 - loss: 1.0370 - val_accuracy: 0.5572 - val_loss: 1.2715\n","Epoch 87/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6042 - loss: 1.0449 - val_accuracy: 0.5566 - val_loss: 1.2676\n","Epoch 88/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6146 - loss: 1.0314 - val_accuracy: 0.5559 - val_loss: 1.2758\n","Epoch 89/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6161 - loss: 1.0293 - val_accuracy: 0.5541 - val_loss: 1.2647\n","Epoch 90/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6229 - loss: 1.0081 - val_accuracy: 0.5486 - val_loss: 1.2642\n","Epoch 91/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 1.0205 - val_accuracy: 0.5564 - val_loss: 1.2432\n","Epoch 92/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6212 - loss: 1.0217 - val_accuracy: 0.5401 - val_loss: 1.3349\n","Epoch 93/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6224 - loss: 1.0048 - val_accuracy: 0.5624 - val_loss: 1.2551\n","Epoch 94/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 1.0064 - val_accuracy: 0.5459 - val_loss: 1.3048\n","Epoch 95/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6256 - loss: 1.0072 - val_accuracy: 0.5589 - val_loss: 1.2577\n","Epoch 96/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6259 - loss: 1.0067 - val_accuracy: 0.5495 - val_loss: 1.2680\n","Epoch 97/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6227 - loss: 1.0048 - val_accuracy: 0.5672 - val_loss: 1.2573\n","Epoch 98/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6237 - loss: 1.0072 - val_accuracy: 0.5621 - val_loss: 1.2324\n","Epoch 99/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6244 - loss: 1.0056 - val_accuracy: 0.5647 - val_loss: 1.2558\n","Epoch 100/200\n","\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6293 - loss: 1.0022 - val_accuracy: 0.5564 - val_loss: 1.2721\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Paths to the dataset\n","train_dir = '/home/laptop-kl-11/personal_project/face_expression_classification_guvi/dataset/train'\n","test_dir = '/home/laptop-kl-11/personal_project/face_expression_classification_guvi/dataset/test'\n","\n","# Constants\n","IMG_HEIGHT, IMG_WIDTH = 48, 48\n","BATCH_SIZE = 32\n","EPOCHS = 200\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","# Load Train Dataset and Split into Training and Validation\n","train_dataset = tf.keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    validation_split=0.25,  # 20% of training data for validation\n","    subset=\"training\",\n","    seed=123,\n","    color_mode=\"grayscale\",\n","    image_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE\n",")\n","\n","validation_dataset = tf.keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    validation_split=0.25,  # 20% of training data for validation\n","    subset=\"validation\",\n","    seed=123,\n","    color_mode=\"grayscale\",\n","    image_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Load Test Dataset\n","test_dataset = tf.keras.utils.image_dataset_from_directory(\n","    test_dir,\n","    image_size=(IMG_HEIGHT, IMG_WIDTH),\n","    color_mode=\"grayscale\",\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Data Augmentation for Training\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.2)\n","])\n","\n","# Apply data augmentation to the training dataset\n","def augment_data(image, label):\n","    image = data_augmentation(image)\n","    return image, label\n","\n","train_dataset = train_dataset.map(augment_data, num_parallel_calls=AUTOTUNE)\n","\n","\n","train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    \n","    Conv2D(64, (3, 3), activation='relu'),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    \n","    Conv2D(128, (3, 3), activation='relu'),\n","    BatchNormalization(),\n","    MaxPooling2D((2, 2)),\n","    \n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.4),\n","    Dense(64, activation='relu'),\n","    Dropout(0.3),\n","    Dense(7, activation='softmax')  \n","])\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='sparse_categorical_crossentropy',  \n","    metrics=['accuracy']\n",")\n","\n","\n","callbacks = [\n","    EarlyStopping(\n","        monitor='val_loss',  \n","        patience=25,         \n","        restore_best_weights=True  \n","    ),\n","    ModelCheckpoint(\n","        filepath='/kaggle/working/emotion_model_tf_data.keras', \n","        monitor='val_loss',\n","        save_best_only=True\n","    )\n","]\n","\n","#training model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=EPOCHS,\n","    callbacks = callbacks\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss: 1.122096\n","Top 1 Accuracy: 58.498189 %\n","Top 2 Accuracy: 76.567289 %\n","Precision: 0.584982\n","Recall: 0.584982\n","F1 Score: 0.584982\n","Confusion Matrix:\n"," [[ 485    0   72   88  111  189   13]\n"," [  48    9   25    6    5   16    2]\n"," [ 160    1  308   79  125  280   71]\n"," [  44    0   34 1555   80   48   13]\n"," [  81    0   53  139  682  262   16]\n"," [ 139    0   93  121  249  631   14]\n"," [  31    0  115   73   54   29  529]] \n","\n"]},{"name":"stderr","output_type":"stream","text":["2024-12-25 17:37:21.913996: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"]}],"source":["import numpy as np\n","from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n","\n","#evaluation with test dataset\n","loss, accuracy = model.evaluate(test_dataset, verbose=0)\n","print(\"Loss: %2.6f\" % loss)\n","\n","# Get predictions and ground truth\n","y_gt = []\n","y_pred_top1 = []\n","y_pred_probs = []\n","\n","# Iterate over the test dataset\n","for images, labels in test_dataset:\n","    # Ground truth\n","    y_gt.extend(labels.numpy())\n","    \n","    # Predictions\n","    probs = model.predict(images, verbose=0)  # Probabilities for each class\n","    y_pred_top1.extend(np.argmax(probs, axis=1))  # Top-1 predictions\n","    y_pred_probs.extend(probs)\n","\n","y_gt = np.array(y_gt)\n","y_pred_top1 = np.array(y_pred_top1)\n","y_pred_probs = np.array(y_pred_probs)\n","\n","# Calculate Top-1 Accuracy\n","acc1 = np.mean(y_pred_top1 == y_gt) * 100\n","print(\"Top 1 Accuracy: %2.6f %%\" % acc1)\n","\n","# Calculate Top-2 Accuracy\n","top2_correct = 0\n","for i in range(len(y_gt)):\n","    top2_preds = np.argsort(y_pred_probs[i])[-2:]  # Top-2 predictions\n","    if y_gt[i] in top2_preds:\n","        top2_correct += 1\n","acc2 = (top2_correct / len(y_gt)) * 100\n","print(\"Top 2 Accuracy: %2.6f %%\" % acc2)\n","\n","# Calculate Precision, Recall, and F1 Score\n","precision = precision_score(y_gt, y_pred_top1, average='micro')\n","recall = recall_score(y_gt, y_pred_top1, average='micro')\n","f1 = f1_score(y_gt, y_pred_top1, average='micro')\n","\n","print(\"Precision: %2.6f\" % precision)\n","print(\"Recall: %2.6f\" % recall)\n","print(\"F1 Score: %2.6f\" % f1)\n","\n","# Confusion Matrix\n","conf_matrix = confusion_matrix(y_gt, y_pred_top1)\n","print(\"Confusion Matrix:\\n\", conf_matrix, '\\n')\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4414645,"sourceId":7583849,"sourceType":"datasetVersion"}],"dockerImageVersionId":30823,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":4}
